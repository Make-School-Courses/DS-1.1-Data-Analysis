{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Probability-Based Statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Handy Dandy Import Statements to Start Off Our Handy Dandy Little Tutorial\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we're going to extend our discussion of descriptive statistics to enter the world of probability-based analysis.\n",
    "\n",
    "_Probability and Statistics_ are two sides of the same coin: a brilliant, shining coin with the power to _end all global problems forever and make you rich_.\n",
    "\n",
    "Now, in all seriousness, to truly understand data and its ever vast symphony of insights just waiting for analysts to extract them, one must understand the relationship between probability, statistical thinking, and data.\n",
    "\n",
    "But before we get into probability and statistics, let's wrap up our knowledge of descriptive statistics and build a bridge into the realm of statistical thinking by talking about **data distributions** and **density functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions and  Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you've probably seen all kinds of datasets with unique distributions. \n",
    "\n",
    "It's no secret that there tend to be... *patterns* regarding the shape that some data assume. \n",
    "\n",
    "How can we apply our understanding of descriptive statistics and mathematical inference to learn more about how data is distributed?\n",
    "\n",
    "Well, up until this point, we've been running our analyses and visualizations on discretized data models. \n",
    "\n",
    "That's right, all the data we've looked at so far we've been thinking of like a **jar of cookies**, with every data point being like a single cookie in the jar.\n",
    "\n",
    "However, we can do a whole lot more statistical inference by treating our data like a **bucket of water**, with infinitely minute changes and assumed variances across our data.\n",
    "\n",
    "Let's go through an example and introduce density functions to help this way of thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the Titanic dataset and run some basic lookups to make sure we have the correct data. \n",
    "\n",
    "PATH = \"./titanic.csv\"\n",
    "df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as always, let's take a quick look at the head of our data to make sure everything went well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know we're working with the appropriate data, for today's exercise, we only really want to look at the **Age** data across our dataset. \n",
    "\n",
    "Let's grab the `Age` column of our data and save it to a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ages = df[\"Age\"]\n",
    "df_ages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, we should really make sure our data is cleared of all NaN values. \n",
    "\n",
    "For this exercise, we don't want to concern ourselves with NaNs and would prefer simply dropping them.\n",
    "\n",
    "So let's drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    38.0\n",
       "2    26.0\n",
       "3    35.0\n",
       "4    35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ages = df_ages[~np.isnan(df_ages)]\n",
    "df_ages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what we want to do is we want to immediately visualize our data. \n",
    "\n",
    "Preferably, let's use a Seaborn histogram to check out what our data's distribution looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1fd7a208>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAEZZJREFUeJzt3X+s3XV9x/Hna1RUUMevQijFFpOK\nOjcBG4ayGCcM0RlhGyQQ4xrB9J9O0Zk4XJMZsy2RaPyxpTNrpIqLARXdIIwopNItLgF3oaBgxTK0\nUC/QUkVXXVDme3+cb+e1Xmjv+Z57z7mfPh/JzTnf7/1+73nlnm9fPfdzvt/PSVUhSWrXb4w7gCRp\nfln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMYtGXcAgOOOO65Wrlw57hiStKjc\neeedj1fV0gNtNxFFv3LlSqampsYdQ5IWlSQ7DmY7h24kqXEHLPokm5LsSnLvjHXHJLk1yfbu9uhu\nfZL8XZIHknwjyRnzGV6SdGAH84r+08D5+627EthcVauAzd0ywBuAVd3XWuATo4kpSRrWAYu+qv4d\n+MF+qy8ArunuXwNcOGP9Z2rgduCoJCeOKqwkae6GHaM/oaoeAehuj+/WnwQ8PGO7nd26X5NkbZKp\nJFO7d+8eMoYk6UBG/WZsZlk36yebVNXGqlpdVauXLj3g2UGSpCENW/SP7RuS6W53det3AifP2G45\nMD18PElSX8MW/Y3Amu7+GuCGGev/tDv75izgR/uGeCRJ43HAC6aSXAu8FjguyU7g/cAHgc8nuRx4\nCLi42/xm4I3AA8BPgbfNQ2ZJ0hwcsOir6tKn+dY5s2xbwLq+oTR/NmzYxPT0nqH3X7bsWNatu2yE\niSTNt4mYAkELZ3p6DytWnDf0/jt23DLCNJIWglMgSFLjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ\n9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUv\nSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1Ljlow7gBaXqamtrF//oaH2XbbsWNatu2zEiSQd\niEWvOdm790lWrDhvqH137LhlxGkkHQyLXgvGvwak8bDotWD8a0AaD9+MlaTGWfSS1DiLXpIa16vo\nk7w7yX1J7k1ybZLnJDklyR1Jtif5XJLDRxVWkjR3Qxd9kpOAdwKrq+rlwGHAJcBVwEerahXwQ+Dy\nUQSVJA2n79DNEuC5SZYARwCPAK8Dru++fw1wYc/HkCT1MHTRV9X3gQ8DDzEo+B8BdwJPVNVT3WY7\ngZP6hpQkDa/P0M3RwAXAKcAy4EjgDbNsWk+z/9okU0mmdu/ePWwMSdIB9Bm6ORf4blXtrqqfA18C\nXg0c1Q3lACwHpmfbuao2VtXqqlq9dOnSHjEkSc+kz5WxDwFnJTkC+B/gHGAKuA24CLgOWAPc0Dek\nftWGDZuYnt4z1L5TU/cMfXWqpMVp6KKvqjuSXA/cBTwFbAU2Av8KXJfkb7p1V48iqH5penrP0GW9\nZcvtI04jadL1muumqt4PvH+/1Q8CZ/b5uZKk0fHKWElqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4\ni16SGmfRS1LjLHpJapxFL0mN6zUFgrRQpqa2sn79h4bad9myY1m37rIRJ5IWD4tei8LevU8OPZHb\njh23jDiNtLg4dCNJjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9\nJDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUuF5Fn+SoJNcn\n+XaSbUleleSYJLcm2d7dHj2qsJKkuev7iv7jwJer6iXAK4BtwJXA5qpaBWzuliVJYzJ00Sd5AfAa\n4GqAqvpZVT0BXABc0212DXBh35CSpOH1eUX/ImA38KkkW5N8MsmRwAlV9QhAd3v8CHJKkobUp+iX\nAGcAn6iq04GfMIdhmiRrk0wlmdq9e3ePGJKkZ9Kn6HcCO6vqjm75egbF/1iSEwG6212z7VxVG6tq\ndVWtXrp0aY8YkqRnMnTRV9WjwMNJTu1WnQN8C7gRWNOtWwPc0CuhJKmXJT33fwfw2SSHAw8Cb2Pw\nn8fnk1wOPARc3PMxJEk99Cr6qrobWD3Lt87p83MlSaPjlbGS1DiLXpIaZ9FLUuMseklqnEUvSY2z\n6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOIte\nkhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuOWjDuANN+mprayfv2H\nhtp32bJjWbfushEnkhaWRa/m7d37JCtWnDfUvjt23DLiNNLCc+hGkhpn0UtS4yx6SWqcRS9JjbPo\nJalxvYs+yWFJtia5qVs+JckdSbYn+VySw/vHlCQNaxSv6K8Ats1Yvgr4aFWtAn4IXD6Cx5AkDalX\n0SdZDvwh8MluOcDrgOu7Ta4BLuzzGJKkfvpeMPUx4L3A87vlY4EnquqpbnkncNJsOyZZC6wFeOEL\nXzh0gA0bNjE9vWfo/b3yUVLrhi76JG8CdlXVnUleu2/1LJvWbPtX1UZgI8Dq1atn3eZgTE/vGfqq\nR/DKR0nt6/OK/mzgzUneCDwHeAGDV/hHJVnSvapfDkz3jylJGtbQY/RV9b6qWl5VK4FLgK9W1VuA\n24CLus3WADf0TilJGtp8nEf/F8CfJ3mAwZj91fPwGJKkgzSS2Suraguwpbv/IHDmKH6uJKk/r4yV\npMZZ9JLUOItekhpn0UtS4yx6SWqcnxkrPYM+HywOsH37d1i16sVD7ev0HBoVi156Bn0+WBxgy5bb\nOfdcP5hc4+XQjSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcp1eOSZ+PQJyauqfXKX+SDi0W/Zj0\n+QjELVtuH3EaSS1z6EaSGmfRS1LjLHpJapxj9NKE6jOhmhOiaSaLXppQfSZUc0I0zeTQjSQ1zqKX\npMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuOGLvok\nJye5Lcm2JPcluaJbf0ySW5Ns726PHl1cSdJc9XlF/xTwnqp6KXAWsC7Jy4Argc1VtQrY3C1LksZk\n6KKvqkeq6q7u/n8D24CTgAuAa7rNrgEu7BtSkjS8kYzRJ1kJnA7cAZxQVY/A4D8D4PhRPIYkaTi9\niz7J84AvAu+qqh/PYb+1SaaSTO3evbtvDEnS0+hV9EmexaDkP1tVX+pWP5bkxO77JwK7Ztu3qjZW\n1eqqWr106dI+MSRJz6DPWTcBrga2VdVHZnzrRmBNd38NcMPw8SRJffX5cPCzgbcC30xyd7fuL4EP\nAp9PcjnwEHBxv4iSpD6GLvqq+hqQp/n2OcP+XEnSaHllrCQ1zqKXpMZZ9JLUuD5vxkqaUFNTW1m/\n/kND7bts2bGsW3fZiBNpnCx6qUF79z7JihXnDbXvjh23jDiNxs2i72HDhk1MT+8Zat+pqXuG/oco\nSXNh0fcwPb1n6LLesuX2EaeRpNkd8kXfZyzTV+WSFoNDvuj7jGX6qlzSYnDIF72kX9Xnr1zwrJ1J\nZNFL+hV9/soFz9qZRF4wJUmNs+glqXEWvSQ1zjF6SSPl9AuTx6KXNFJOvzB5HLqRpMZZ9JLUOIte\nkhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DinQJDUhA0bNjE9vWeofVufY8eil9SE\n6ek9zrHzNCx6SROjz8yXU1P39PpkrJZZ9JImRp+ZL7dsuX3Eadrhm7GS1DiLXpIaZ9FLUuPmpeiT\nnJ/k/iQPJLlyPh5DknRwRl70SQ4DNgBvAF4GXJrkZaN+HEnSwZmPs27OBB6oqgcBklwHXAB8ax4e\nS5J663Na5/bt32HVqhcP/dgLcbHWfBT9ScDDM5Z3Ar87D48jSSPR97TOc88d/vz9hbhYK1U12h+Y\nXAy8vqre3i2/FTizqt6x33ZrgbXd4qnA/UM83HHA4z3izhdzzc2k5oLJzWauuZnUXNAv24qqWnqg\njebjFf1O4OQZy8uB6f03qqqNwMY+D5RkqqpW9/kZ88FcczOpuWBys5lrbiY1FyxMtvk46+Y/gVVJ\nTklyOHAJcOM8PI4k6SCM/BV9VT2V5M+ArwCHAZuq6r5RP44k6eDMy1w3VXUzcPN8/Oz99Br6mUfm\nmptJzQWTm81cczOpuWABso38zVhJ0mRxCgRJatyiLPpJmmIhyaYku5LcO2PdMUluTbK9uz16DLlO\nTnJbkm1J7ktyxSRkS/KcJF9Pck+X6wPd+lOS3NHl+lz3Rv6CS3JYkq1JbpqUXEm+l+SbSe5OMtWt\nG/sx1uU4Ksn1Sb7dHWuvGne2JKd2v6t9Xz9O8q5x5+qyvbs77u9Ncm3372Hej7FFV/QTOMXCp4Hz\n91t3JbC5qlYBm7vlhfYU8J6qeilwFrCu+z2NO9uTwOuq6hXAacD5Sc4CrgI+2uX6IXD5Aufa5wpg\n24zlScn1+1V12ozT8Mb9PO7zceDLVfUS4BUMfndjzVZV93e/q9OAVwI/Bf553LmSnAS8E1hdVS9n\ncLLKJSzEMVZVi+oLeBXwlRnL7wPeN+ZMK4F7ZyzfD5zY3T8RuH8Cfm83AH8wSdmAI4C7GFw5/Tiw\nZLbneAHzLGdQAK8DbgIyIbm+Bxy337qxP4/AC4Dv0r3XN0nZZmQ5D/iPScjFL2cNOIbBiTA3Aa9f\niGNs0b2iZ/YpFk4aU5anc0JVPQLQ3R4/zjBJVgKnA3cwAdm64ZG7gV3ArcB/AU9U1VPdJuN6Tj8G\nvBf4Rbd87ITkKuCWJHd2V5TDBDyPwIuA3cCnuuGuTyY5ckKy7XMJcG13f6y5qur7wIeBh4BHgB8B\nd7IAx9hiLPrMss5Th55GkucBXwTeVVU/HncegKr63xr8Wb2cwSR4L51ts4XMlORNwK6qunPm6lk2\nHcexdnZVncFguHJdkteMIcNslgBnAJ+oqtOBnzC+IaRf0411vxn4wrizAHTvCVwAnAIsA45k8Jzu\nb+TH2GIs+oOaYmHMHktyIkB3u2scIZI8i0HJf7aqvjRJ2QCq6glgC4P3EI5Ksu+6jnE8p2cDb07y\nPeA6BsM3H5uAXFTVdHe7i8FY85lMxvO4E9hZVXd0y9czKP5JyAaDEr2rqh7rlsed61zgu1W1u6p+\nDnwJeDULcIwtxqJfDFMs3Ais6e6vYTA+vqCSBLga2FZVH5mUbEmWJjmqu/9cBgf/NuA24KJx5aqq\n91XV8qpayeCY+mpVvWXcuZIcmeT5++4zGHO+lwk4xqrqUeDhJKd2q85hMB352LN1LuWXwzYw/lwP\nAWclOaL797nv9zX/x9i43iTp+abGG4HvMBjbXT/mLNcyGG/7OYNXOJczGNvdDGzvbo8ZQ67fY/An\n4DeAu7uvN447G/A7wNYu173AX3XrXwR8HXiAwZ/azx7jc/pa4KZJyNU9/j3d1337jvdxP48z8p0G\nTHXP578AR09CNgZv9O8BfnPGuknI9QHg292x/0/AsxfiGPPKWElq3GIcupEkzYFFL0mNs+glqXEW\nvSQ1zqKXpMZZ9DrkJfmjJJXkJePOIs0Hi14aXFjzNQYXSknNseh1SOvmAjqbwYVul3TrfiPJP3Tz\nht+U5OYkF3Xfe2WSf+smGPvKvkvqpUlm0etQdyGD+dS/A/wgyRnAHzOYevq3gbczmDp239xBfw9c\nVFWvBDYBfzuO0NJczMuHg0uLyKUMJi+DwWRmlwLPAr5QVb8AHk1yW/f9U4GXA7cOpirhMAbTX0gT\nzaLXISvJsQxmqXx5kmJQ3MVghshZdwHuq6pXLVBEaSQcutGh7CLgM1W1oqpWVtXJDD4x6XHgT7qx\n+hMYTHIGg08oWprk/4dykvzWOIJLc2HR61B2Kb/+6v2LDD4UYieDGQb/kcEnc/2oqn7G4D+Hq5Lc\nw2BG0FcvXFxpOM5eKc0iyfOqam83vPN1Bp/y9Oi4c0nDcIxemt1N3QekHA78tSWvxcxX9JLUOMfo\nJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuP+D54sHzSEn0HqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ff2f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Run this code cell to see the visualization below!\n",
    "sns.distplot(df_ages, hist=True, kde=False,\n",
    "             bins=20, color=\"darkblue\",\n",
    "             hist_kws={\"edgecolor\": \"black\"},\n",
    "             kde_kws={\"linewidth\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're used to seeing data distributions like this before.\n",
    "\n",
    "However, want we want to see is how we can convert data that's obviously discretized and unitized into something more fluid and contiguous. \n",
    "\n",
    "**In the previous cell, change the** `kde=False` **argument to say** `kde=True` **and observe the changes made!**\n",
    "\n",
    "Notice the new function line imposed above our histogram?\n",
    "\n",
    "This is called a ***Kernel Density Function*** or ***Probability Density Function***. \n",
    "\n",
    "Understanding exactly what means isn't too important, but what is important is to understand that a density function is simply a mathematical approximation as to the expected shape and layout of our data if we had _infinite data points_ that follow our dataset's distribution.\n",
    "\n",
    "As we saw in the last in-class notebook, getting the exact values for percentile and relative position across our data can be pretty tricky – even with the most complex mathematical structure we can come up with – if we're only dealing with discontinuous, discretized data.\n",
    "\n",
    "But by applying a density function to our data and assuming a continuity in values, we can get **much more specific and relevant** measures of relative position and descriptive statistics from our data!\n",
    "\n",
    "Let's see how that works with a little bit of SciPy Stats module trickery!\n",
    "\n",
    "We want to know the area under and over the curve at a certain age, and we want to know the *exact values* of both.\n",
    "\n",
    "That means our methods that we built last notebook, while effective to an extent, are no longer satisfactory.\n",
    "\n",
    "We need to call in some backup! `SciPy Stats` to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Use the following function regarding density function calculations to answer the questions below._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the cumulative area to the **left** of a data point, use the **cumulative density function**.\n",
    "<br>\n",
    "<center>`st.norm.cdf()`</center>\n",
    "<br>\n",
    "\n",
    "To compute the cumulative area to the **right** of a data point, use the **survival function**.\n",
    "<br>\n",
    "<center>`st.norm.sf()`</center>\n",
    "<br>\n",
    "\n",
    "NOTE: Don't worry too much about what these are doing under the hood, we'll talk about that at a later date! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_ages.values.flatten()\n",
    "\n",
    "def compute_percentiles_with_pdf(dataset, value, area=\"left\"):\n",
    "    \"\"\" Main function to determine percentile/quartile ranges using PDF/KDF estimators. \"\"\"\n",
    "    mean, std_dev = np.mean(dataset), np.std(dataset)\n",
    "    Z = (value - mean) / std_dev\n",
    "    if area == \"left\":\n",
    "        return stats.norm.cdf(Z)\n",
    "    if area == \"right\":\n",
    "        return stats.norm.sf(Z)\n",
    "\n",
    "# TODO: Uncomment the following line to answer the questions below!\n",
    "# compute_percentiles_with_pdf(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the **exact percentile** at the age of 35?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What is the **exact percentile** at the age of 77?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What **exact proportion of data** is between the age range of 45 and 55?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- **Exactly how much of our data** is above the age of 25?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What **exact proportion of data** is below the age of 10 and above the age of 60?\n",
    "\n",
    "`Write your response here!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function and some tools that can get us relative positional data values based on percentile in an exact nature! \n",
    "\n",
    "We'll discuss soon how and why this matters as we dive into statistical inference and deeper analytical thinking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief Introduction to Probabilistic Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability is all about the **chances of an event occurring** or how likely an event is to occur, in a set of events.\n",
    "\n",
    "If you really think about it, you've been thinking about probability all of your life! \n",
    "\n",
    "Ever wondered about...\n",
    "\n",
    "> -  The chances of it raining today\n",
    "> -  The chances of winning the lottery\n",
    "> -  The chances of getting hired at Google\n",
    "\n",
    "That's probabilistic thinking! \n",
    "\n",
    "We can draw immediate connections from the world of probabilistic thinking to the world of statistical inference and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematics, probability is modeled by the following expression:\n",
    "\n",
    "$P(A)= \\frac{Count of A }{sample Space}$\n",
    "\n",
    "Don't fear at the sight of equations and non-numerical variables – this is much simpler than it looks! \n",
    "\n",
    "All this translates to is that **the probability of Event A occurring** in a set of observed events in _Sample Space S_ is equal to **the number of occurrences of Event A** across _Sample Space S_ divided by **the total number of observed events**. \n",
    "\n",
    "Note that since the number of occurrences of a single event can never be bigger than the total events that can occur in the sample space, the probability of an event will always be within the range: [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer our probability estimate is to zero (0), the less likely it is for our event in-question to occur, with a value of zero (0) indicating that our observed event didn't occur at all. \n",
    "\n",
    "The closer our probability estimate is to one (1), the more likely it is for our event in-question to occur, with a value of one (1) indicating that our observed event occurs in every observable instance.\n",
    "\n",
    "\n",
    "<img src=\"https://www2.southeastern.edu/Academics/Faculty/dgurney/Math241/StatTopics/PrbScl4.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll often see this represented in data sets in a number of formats. \n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "| Won Lottery |\n",
    "| ----|\n",
    "| yes |\n",
    "| no  |\n",
    "| no  |\n",
    "| no  |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Hired by Google |\n",
    "|------|\n",
    "| false|\n",
    "| true |\n",
    "| true |\n",
    "| false|\n",
    "\n",
    "<br>\n",
    "\n",
    "Any kind of distribution of values where our data can take one of multiple, separately-occurring states indicates that we can think about the probability of each state (event) occurring on its own! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability on the surface simply describes the likelihood of individual events, but one concept we haven't spoken about yet is whether or not certain events are **dependent** on one another or not. \n",
    "\n",
    "As it turns out, understanding the interdependency of event occurrences is critical to fully grasping the role of probability and statistics in data science.\n",
    "\n",
    "Let's start with some conceptual examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip a coin three times. What is the probability of each event (H/T) occurring for each coin flip?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you're likely already aware of, we consider the probability of each event occurrence across multiple trials to be **independent**. \n",
    "\n",
    "In other words, the occurrence of one coin flip _does not influence_ the occurrence of another coin flip in any way. \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "Now let's think on that... if the events were not independent – rather, they were **dependent** events – what would we have to consider with each subsequent coin flip's probabilistic outcomes?\n",
    "\n",
    "We would likely have to consider that every _N_-th trial of our test affects the probability of the outcomes of every (_N + 1_)-th trial.\n",
    "\n",
    "If that doesn't make much sense or is still a little unclear, have no fear. \n",
    "\n",
    "This is when probability and statistics gets *funky*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider we have a bag of marbles: two are **blue**, and three are **red**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask a simple probabilistic question: \n",
    "\n",
    "### _What is the probability of drawing a red marble?_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model the probability of each outcome as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mathsisfun.com/data/images/probability-marbles-tree1.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the probability of each outcome occurrence at the start is the number of marbles of one color divided by the total number of marbles. \n",
    "\n",
    "However, let's extend this problem and think more critically with the following, more complicated question:\n",
    "\n",
    "### _What is the probability of drawing another red marble?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem simple enough, but consider that the question is particularly asking about drawing \"_another red marble_\". \n",
    "\n",
    "That means that the probability of drawing the second red marble is **inherently dependent** on the probability of drawing the first red marble!\n",
    "\n",
    "This poses a more interested case that can be modeled by the following diagram:\n",
    "\n",
    "<img src=\"https://www.mathsisfun.com/data/images/probability-marbles-tree2.svg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This probability outcomes diagram represents all the possible outcomes present over two trials of drawing marbles from the bag, with an important stipulation:\n",
    "\n",
    "_Since we are not putting the first marble back into the bag, the probability outcomes for a second marble pick are dependent on the outcomes of the first marble picks!_\n",
    "\n",
    "So let's start with an easier dependent probabilities question that'll illustrate how probabilities can affect one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _What is the probability of drawing two red marbles?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's carefully consider the question. \n",
    "\n",
    "In this case, we don't care about each independent event as much as we care about the outcome of two red marbles. \n",
    "\n",
    "This means that we can simply grab the **product of all relevant probabilities**. \n",
    "\n",
    "In this case, that means that the _probability of drawing two red marbles_ is $ \\frac{3}{5} * \\frac{2}{4} $, which is equal to $ \\frac{3}{10} $ or 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is just the tip of the iceberg. \n",
    "\n",
    "Let's consider a more advanced probability question, now bringing more conditional probability into the mix.\n",
    "\n",
    "### _What is the probability of drawing a blue marble given that a red marble was originally drawn?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's carefully break this down, as things are not as simple as they seem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know the _probability of drawing a blue marble_ given that _the event of drawing a red marble_ has already occurred.\n",
    "\n",
    "This is known in statistics as **conditional probability**, as it is attempting to determine a probabalistic outcome given a certain conditional event occurrence.\n",
    "\n",
    "In other words, given that a red marble was drawn, what is the chance of drawing a blue marble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can simply observe the state of the bag after having drawn the previous red marble and calculate the probability of drawing the blue marble.\n",
    "\n",
    "Which in this case, since drawing a red marble leaves _two blues_ and _two reds_, the probability of then drawing a blue marble is $ \\frac{1}{2} $. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general cases, the conditional probability of an event is described by the following equation.\n",
    "\n",
    "<br><img src=\"https://www.mathsisfun.com/data/images/probability-independent-formula2.gif\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be described as **the probability of event B given event A** is equal to _the probability of events A and B occurring_ divided by _the probability of event A_. \n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Example Question: I Scream for Ice Cream_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% of your friends like Chocolate, and 35% like Chocolate AND like Strawberry.\n",
    "\n",
    "What percent of those who like Chocolate also like Strawberry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to refactor the question to fit our conditional probability model:\n",
    "\n",
    "- Given that some friends like _Chocolate_, what is the probability that they like _Strawberry_ as well?\n",
    "\n",
    "We can now attribute our events to the question parameters!\n",
    "\n",
    "- **Event A: Chocolate**\n",
    "- **Event B: Strawberry**\n",
    "\n",
    "We're already given the following:\n",
    "\n",
    "- $ P( Chocolate ) = 0.7 $\n",
    "- $ P( Chocolate \\cap Strawberry) = 0.35 $\n",
    "\n",
    "And asked the following:\n",
    "\n",
    "- $ P( Strawberry \\mid Chocolate ) = ? $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, our conditional probability model now looks a little like this:\n",
    "\n",
    "$ P( Strawberry \\mid Chocolate ) = \\frac{P( Chocolate \\cap Strawberry )}{P( Chocolate )} $\n",
    "\n",
    "Plugging in our parameters gives us the following answer:\n",
    "\n",
    "$ P( Strawberry \\mid Chocolate ) = \\frac{0.35}{0.7} = 0.5 $\n",
    "\n",
    "...which confirms to us that 50% of your friends who like chocolate also like strawberry. \n",
    "\n",
    "Makes sense when you think about it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Answer the following questions using the Titanic dataset and your understanding of Conditional Probability._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of passengers survived *given* that they were male?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What percentage of passengers paid more than $50 *given* that they embarked in Cherbourg?\n",
    "\n",
    "`Write your response here!`\n",
    "\n",
    "- What percentage of passengers died *given* that they had siblings/spouses OR had parents/children with them on board?\n",
    "\n",
    "`Write your response here!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of passengers who died given that they're female: 25.8%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Answer the following questions using conditional probability statements.\n",
    "# NOTE: To make it clearer, I advise using conditional probability arguments like so...\n",
    "\n",
    "# EXAMPLE: What proportion of passengers died, given that they were female?\n",
    "arg_female = (df[\"Sex\"] == \"female\")\n",
    "females = df[arg_female]\n",
    "\n",
    "arg_females_died = (females[\"Survived\"] == 0)\n",
    "percent_died_given_female = len(females[arg_females_died]) / len(females)\n",
    "print(\"Percentage of passengers who died given that they're female: {}%\".format(round(100 * percent_died_given_female, 2)))\n",
    "\n",
    "# TODO: WRITE YOUR CODE TO ANSWER THE ABOVE QUESTIONS HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've worked through enough of probability, let's change topics to something a little more directly relevant in data science: the ***Normal Distribution***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we should have some familiarity of the types of distributions that we see in data science. \n",
    "\n",
    "After all, distributions are just arrangements of data values in space, and we're interested as data science to detect patterns in that space! \n",
    "\n",
    "There is one distribution that requires a good amount of attention, due to its relevance in data science for statistical inference and analysis.\n",
    "\n",
    "That is the ***Normal (Gaussian) Distribution***, otherwise known as the Bell Curve model.\n",
    "\n",
    "<br><img src=\"https://ds055uzetaobb.cloudfront.net/image_optimizer/1dbcc5a80e3fb541aa4678fcff58bb26ca717902.png\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Distribution has several properties pertaining to its spread and central tendency that make it distinctive and unique across nearly all other distributive types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, the Normal Distribution is unique in that it is one of the few distributions where the three key measures of central tendency are _equivalent_.\n",
    "\n",
    "That's right: **the mean, median, and mode for a Normal Distribution are all the same value**.\n",
    "\n",
    "You can probably guess that it's the value at the dead center of the Normal Distribution, and you'd be right! \n",
    "\n",
    "It's the value that simultaneously is the average value, middle value, and most commonly occurring value across your data. \n",
    "\n",
    "This allows us to make inferences regarding the data's distribution, including but not limited to the following:\n",
    "- Symmetry across the center value\n",
    "- Graphical peak at the mean/median/mode\n",
    "- Tails get progressively smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Distribution also is unique in having a direct known relationship between the standard deviation and the range of data captured across the dataset. \n",
    "\n",
    "In other words, **the standard deviation for a Normal Distribution can tell you how much data is contained within its bounds**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often called _the 68-95-99.7 Rule_. \n",
    "\n",
    "<br><img src=\"http://www.oswego.edu/~srp/stats/images/normal_34.gif\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we see different degrees of data captured within bounds that are created by the standard deviation. \n",
    "\n",
    "So to make it clear:\n",
    "- 68% of the data is captured within one standard deviation from the mean.\n",
    "- 95% of the data is captured within two standard deviations from the mean.\n",
    "- 99.7% of the data is captured within three standard deviations from the mean.\n",
    "\n",
    "This makes it very effective for statistical testing and analysis to be able to grab set quantities of data using the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next class, we'll connect our understanding of the Normal Distribution with more complex statistical topics to give you even more power in manipulating, analyzing, and understanding your data.\n",
    "\n",
    "**Excelsior!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
